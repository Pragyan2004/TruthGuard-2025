{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3795e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Pragyan\n",
      "[nltk_data]     Kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Pragyan\n",
      "[nltk_data]     Kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Pragyan\n",
      "[nltk_data]     Kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32943b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    fake_news = pd.read_csv('Fake.csv')\n",
    "    true_news = pd.read_csv('True.csv')\n",
    "    fake_news['label'] = 0  \n",
    "    true_news['label'] = 1  \n",
    "    df = pd.concat([fake_news, true_news], axis=0)\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"Dataset files not found. Creating sample data for demonstration...\")\n",
    "    \n",
    "    sample_data = {\n",
    "        'text': [\n",
    "            \"Breaking: Scientists discover revolutionary cure for all diseases!\",\n",
    "            \"The government announced new economic policies today.\",\n",
    "            \"Aliens landed in New York City, officials confirm!\",\n",
    "            \"The stock market showed moderate gains this quarter.\",\n",
    "            \"Celebrity reveals secret to eternal youth - doctors hate this!\",\n",
    "            \"New study shows benefits of regular exercise and balanced diet.\",\n",
    "            \"You won't believe what this politician said about the moon landing!\",\n",
    "            \"The weather forecast predicts rain for the weekend.\",\n",
    "            \"Secret pyramid discovered under Antarctica ice!\",\n",
    "            \"Local community organizes charity event for homeless shelter.\"\n",
    "        ],\n",
    "        'label': [0, 1, 0, 1, 0, 1, 0, 1, 0, 1]  # 0: fake, 1: true\n",
    "    }\n",
    "    df = pd.DataFrame(sample_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac2dc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(\"Missing values:\")\n",
    "print(df.isnull().sum())\n",
    "df = df.dropna(subset=['text'])\n",
    "\n",
    "print(\"Class Distribution:\")\n",
    "print(df['label'].value_counts())\n",
    "print(\"\\nClass Proportions:\")\n",
    "print(df['label'].value_counts(normalize=True))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='label', data=df)\n",
    "plt.title('Class Distribution (0: Fake, 1: True)')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocess text by:\n",
    "    1. Converting to lowercase\n",
    "    2. Removing special characters and digits\n",
    "    3. Tokenizing\n",
    "    4. Removing stopwords\n",
    "    5. Lemmatizing\n",
    "    \"\"\"\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "        tokens = word_tokenize(text)\n",
    "        tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
    "        return ' '.join(tokens)\n",
    "    else:\n",
    "        return ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3862072",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Preprocessing text data...\")\n",
    "df['cleaned_text'] = df['text'].apply(preprocess_text)\n",
    "print(\"\\nOriginal vs Cleaned Text Examples:\")\n",
    "for i in range(3):\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(\"Original:\", df['text'].iloc[i][:100] + \"...\")\n",
    "    print(\"Cleaned:\", df['cleaned_text'].iloc[i][:100] + \"...\")\n",
    "df['text_length'] = df['cleaned_text'].apply(len)\n",
    "df['word_count'] = df['cleaned_text'].apply(lambda x: len(x.split()))\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(data=df, x='text_length', hue='label', bins=50)\n",
    "plt.title('Text Length Distribution by Class')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(data=df, x='label', y='text_length')\n",
    "plt.title('Text Length by Class')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f869435c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['cleaned_text']\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "\n",
    "print(\"Creating TF-IDF features...\")\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words='english'\n",
    ")\n",
    "\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "print(f\"TF-IDF features shape: {X_train_tfidf.shape}\")\n",
    "print(\"Training Logistic Regression model...\")\n",
    "lr_model = LogisticRegression(\n",
    "    random_state=42,\n",
    "    max_iter=1000,\n",
    "    C=1.0\n",
    ")\n",
    "\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test_tfidf)\n",
    "\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    \"\"\"Evaluate model performance\"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\n{model_name} Performance:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n",
    "lr_metrics = evaluate_model(y_test, y_pred_lr, \"Logistic Regression\")\n",
    "print(\"Training additional models...\")\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "y_pred_nb = nb_model.predict(X_test_tfidf)\n",
    "nb_metrics = evaluate_model(y_test, y_pred_nb, \"Naive Bayes\")\n",
    "svm_model = SVC(random_state=42)\n",
    "svm_model.fit(X_train_tfidf, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test_tfidf)\n",
    "svm_metrics = evaluate_model(y_test, y_pred_svm, \"SVM\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea181aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "max_length = 200\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_length, padding='post')\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_length, padding='post')\n",
    "print(f\"Padded sequences shape: {X_train_pad.shape}\")\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "lstm_model = Sequential([\n",
    "    Embedding(vocab_size, 100, input_length=max_length),\n",
    "    Bidirectional(LSTM(64, return_sequences=True)),\n",
    "    Dropout(0.5),\n",
    "    Bidirectional(LSTM(32)),\n",
    "    Dropout(0.5),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "lstm_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "print(\"LSTM Model Summary:\")\n",
    "lstm_model.summary()\n",
    "\n",
    "print(\"Training LSTM model...\")\n",
    "history = lstm_model.fit(\n",
    "    X_train_pad, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "y_pred_lstm_proba = lstm_model.predict(X_test_pad)\n",
    "y_pred_lstm = (y_pred_lstm_proba > 0.5).astype(int).flatten()\n",
    "\n",
    "lstm_metrics = evaluate_model(y_test, y_pred_lstm, \"LSTM\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "models_comparison = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Naive Bayes', 'SVM', 'LSTM'],\n",
    "    'Accuracy': [lr_metrics[0], nb_metrics[0], svm_metrics[0], lstm_metrics[0]],\n",
    "    'Precision': [lr_metrics[1], nb_metrics[1], svm_metrics[1], lstm_metrics[1]],\n",
    "    'Recall': [lr_metrics[2], nb_metrics[2], svm_metrics[2], lstm_metrics[2]],\n",
    "    'F1-Score': [lr_metrics[3], nb_metrics[3], svm_metrics[3], lstm_metrics[3]]\n",
    "})\n",
    "\n",
    "print(\"Model Comparison:\")\n",
    "print(models_comparison)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "metrics_to_plot = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "\n",
    "for i, metric in enumerate(metrics_to_plot, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    sns.barplot(x='Model', y=metric, data=models_comparison)\n",
    "    plt.title(f'{metric} Comparison')\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "false_positives = X_test[(y_test == 0) & (y_pred_lr == 1)]\n",
    "false_negatives = X_test[(y_test == 1) & (y_pred_lr == 0)]\n",
    "\n",
    "print(f\"False Positives (Fake news predicted as real): {len(false_positives)}\")\n",
    "print(f\"False Negatives (Real news predicted as fake): {len(false_negatives)}\")\n",
    "\n",
    "\n",
    "if len(false_positives) > 0:\n",
    "    print(\"\\nFalse Positive Examples:\")\n",
    "    for i, text in enumerate(false_positives.head(3)):\n",
    "        print(f\"{i+1}. {text[:100]}...\")\n",
    "\n",
    "if len(false_negatives) > 0:\n",
    "    print(\"\\nFalse Negative Examples:\")\n",
    "    for i, text in enumerate(false_negatives.head(3)):\n",
    "        print(f\"{i+1}. {text[:100]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba700f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import joblib\n",
    "print(\"Saving models...\")\n",
    "\n",
    "with open('logistic_regression_model.pkl', 'wb') as f:\n",
    "    pickle.dump(lr_model, f)\n",
    "\n",
    "with open('tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf_vectorizer, f)\n",
    "lstm_model.save('lstm_model.h5')\n",
    "\n",
    "with open('tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "models_dict = {\n",
    "    'logistic_regression': lr_model,\n",
    "    'naive_bayes': nb_model,\n",
    "    'svm': svm_model,\n",
    "    'tfidf_vectorizer': tfidf_vectorizer,\n",
    "    'tokenizer': tokenizer\n",
    "}\n",
    "\n",
    "joblib.dump(models_dict, 'all_models.pkl')\n",
    "\n",
    "print(\"All models saved successfully!\")\n",
    "\n",
    "def predict_news(text, model_type='logistic'):\n",
    "    \"\"\"\n",
    "    Predict whether a news article is real or fake\n",
    "    \n",
    "    Parameters:\n",
    "    text (str): News article text\n",
    "    model_type (str): Type of model to use ('logistic', 'lstm')\n",
    "    \n",
    "    Returns:\n",
    "    dict: Prediction results\n",
    "    \"\"\"\n",
    "    cleaned_text = preprocess_text(text)\n",
    "    \n",
    "    if model_type == 'logistic':\n",
    "        text_tfidf = tfidf_vectorizer.transform([cleaned_text])\n",
    "        \n",
    "        prediction = lr_model.predict(text_tfidf)[0]\n",
    "        probability = lr_model.predict_proba(text_tfidf)[0]\n",
    "        \n",
    "    elif model_type == 'lstm':\n",
    "        text_seq = tokenizer.texts_to_sequences([cleaned_text])\n",
    "        text_pad = pad_sequences(text_seq, maxlen=max_length, padding='post')\n",
    "        probability = lstm_model.predict(text_pad)[0][0]\n",
    "        prediction = 1 if probability > 0.5 else 0\n",
    "        probability = [1 - probability, probability]  \n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Model type must be 'logistic' or 'lstm'\")\n",
    "    \n",
    "    result = {\n",
    "        'prediction': 'Real News' if prediction == 1 else 'Fake News',\n",
    "        'confidence': max(probability),\n",
    "        'fake_probability': probability[0],\n",
    "        'real_probability': probability[1],\n",
    "        'text_preview': text[:100] + '...' if len(text) > 100 else text\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "test_samples = [\n",
    "    \"Breaking: Scientists discover amazing cure that makes all diseases disappear instantly!\",\n",
    "    \"The government announced new economic policies aimed at stabilizing the market.\",\n",
    "    \"Aliens have been confirmed to be living among us according to secret documents!\",\n",
    "    \"Local community raises funds for new park renovation project.\"\n",
    "]\n",
    "\n",
    "print(\"Testing Prediction Function:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, text in enumerate(test_samples, 1):\n",
    "    result = predict_news(text)\n",
    "    print(f\"\\nSample {i}:\")\n",
    "    print(f\"Text: {result['text_preview']}\")\n",
    "    print(f\"Prediction: {result['prediction']}\")\n",
    "    print(f\"Confidence: {result['confidence']:.2%}\")\n",
    "    print(f\"Fake Probability: {result['fake_probability']:.2%}\")\n",
    "    print(f\"Real Probability: {result['real_probability']:.2%}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FAKE NEWS DETECTION SYSTEM - SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Dataset size: {len(df)} articles\")\n",
    "print(f\"Training set: {len(X_train)} articles\")\n",
    "print(f\"Test set: {len(X_test)} articles\")\n",
    "print(f\"Best model: Logistic Regression\")\n",
    "print(f\"Best accuracy: {lr_metrics[0]:.2%}\")\n",
    "print(f\"Files created:\")\n",
    "print(\"  - logistic_regression_model.pkl (Logistic Regression model)\")\n",
    "print(\"  - tfidf_vectorizer.pkl (TF-IDF vectorizer)\")\n",
    "print(\"  - lstm_model.h5 (LSTM model)\")\n",
    "print(\"  - tokenizer.pkl (Tokenizer for LSTM)\")\n",
    "print(\"  - all_models.pkl (All models combined)\")\n",
    "print(\"  - fake_news_app.py (Streamlit web app)\")\n",
    "print(\"\\nTo run the web app: streamlit run fake_news_app.py\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "New_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
